{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8676fc7c",
   "metadata": {},
   "source": [
    "# Which Bird Are You\n",
    "Recognising birds by their song using CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d56283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40122f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a plot of number of images per class for all classes\n",
    "bird_dirs = [d for d in os.listdir(\"data\") if os.path.isdir(os.path.join(\"data\", d))]\n",
    "num_images_per_class = []\n",
    "for bird in bird_dirs:\n",
    "    bird_dir = os.path.join(\"data\", bird)\n",
    "    num_images = len(os.listdir(bird_dir))\n",
    "    num_images_per_class.append(num_images)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(bird_dirs, num_images_per_class)\n",
    "plt.xticks(rotation=90, fontsize=4)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Bird Species\")\n",
    "plt.ylabel(\"Number of Images (log scale)\")\n",
    "plt.title(\"Number of Images per Bird Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same plot but now sorted by number of images\n",
    "sorted_bird_dirs = [x for _, x in sorted(zip(num_images_per_class, bird_dirs))]\n",
    "sorted_num_images_per_class = sorted(num_images_per_class)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sorted_bird_dirs, sorted_num_images_per_class)\n",
    "plt.xticks(rotation=90, fontsize=4)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Bird Species (sorted)\")\n",
    "plt.ylabel(\"Number of Images (log scale)\")\n",
    "plt.title(\"Number of Images per Bird Species (sorted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13c50b",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61aaf5411a0b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "image_size = (128, 128)\n",
    "seed = 30\n",
    "\n",
    "# Get 4 random bird species\n",
    "all_birds = os.listdir(\"data\")\n",
    "random.seed(seed)\n",
    "selected_birds = random.sample(all_birds, 4)\n",
    "print(f\"Selected birds: {selected_birds}\")\n",
    "\n",
    "# images  per class\n",
    "for bird in selected_birds:\n",
    "    bird_dir = os.path.join(\"data\", bird)\n",
    "    num_images = len(os.listdir(bird_dir))\n",
    "    print(f\"{bird}: {num_images} images\")\n",
    "\n",
    "# If you need train/val split, repeat for both\n",
    "train_dataset, val_dataset = image_dataset_from_directory(\n",
    "    \"data\",\n",
    "    class_names=selected_birds,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# Preprocessing: Normalize pixel values to [-1, 1]\n",
    "normalization_layer = keras.layers.Rescaling(1.0 / 127.5, offset=-1.0)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "if False:\n",
    "    f = 0.2\n",
    "\n",
    "    train_dataset = train_dataset.take(int(f * len(train_dataset)))\n",
    "    val_dataset = val_dataset.take(int(f * len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14efd80",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_bird = {\n",
    "    i: name for i, name in enumerate(selected_birds)\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        image = (np.array(images[i]) + 1) / 2\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        idx = int(labels[i])\n",
    "        plt.title(f\"{idx_to_bird[idx]} (#{idx})\")\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6d3e6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2650c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (*image_size, 1)\n",
    "num_classes = len(selected_birds)\n",
    "\n",
    "# Model using Functional API\n",
    "inputs = keras.layers.Input(shape=input_shape)\n",
    "x = keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_1\")(inputs)\n",
    "x = keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_2\")(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pooling2d\")(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_3\")(x)\n",
    "x = keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_4\")(x)\n",
    "x = keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling2d\")(x)\n",
    "# x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"dense\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"bird_classifier\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=opt,\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12326b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "os.makedirs(\"epochs\", exist_ok=True)\n",
    "epochs = 20\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=\"epochs/model_at_epoch_{epoch}.keras\"),\n",
    "    TqdmCallback(verbose=1),\n",
    "]\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Model input shape: {model.input_shape}\")\n",
    "print(f\"Model output shape: {model.output_shape}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7ff8b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['acc'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy over Epochs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33298674a48a1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 9))\n",
    "\n",
    "# Get one batch from the validation dataset\n",
    "for images, labels in val_dataset.take(1):\n",
    "    predictions = model(images, training=False)\n",
    "\n",
    "    for i in range(min(6, len(images))):\n",
    "        image = (np.array(images[i]) + 1) / 2\n",
    "\n",
    "        ax = plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "        true_idx = int(labels[i])\n",
    "        predicted_idx = np.argmax(predictions[i])\n",
    "\n",
    "        true_label = idx_to_bird[true_idx]\n",
    "        predicted_label = idx_to_bird[predicted_idx]\n",
    "\n",
    "        color = 'green' if true_idx == predicted_idx else 'red'\n",
    "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", color=color)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f90c5c",
   "metadata": {},
   "source": [
    "## What Has the Model Learned\n",
    "We will use GradCAM to visualize which parts of the image the model uses to determine the prediction label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmap for a given image.\n",
    "    \n",
    "    Args:\n",
    "        img_array: Input image array\n",
    "        model: Trained model\n",
    "        last_conv_layer_name: Name of the last convolutional layer\n",
    "        pred_index: Target class index (if None, uses predicted class)\n",
    "    \n",
    "    Returns:\n",
    "        heatmap: Grad-CAM heatmap\n",
    "    \"\"\"\n",
    "    # Create a model that maps the input image to the activations of the last conv layer\n",
    "    # and the output predictions\n",
    "    grad_model = keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    \n",
    "    # Gradient of the output neuron with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    \n",
    "    # Vector of mean intensity of the gradient over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Multiply each channel in the feature map array by importance of that channel\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    # Normalize the heatmap between 0 & 1 for visualization\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "\n",
    "def save_and_display_gradcam(img, heatmap, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Superimpose the heatmap on original image.\n",
    "    \n",
    "    Args:\n",
    "        img: Original image (normalized to [-1, 1])\n",
    "        heatmap: Grad-CAM heatmap\n",
    "        alpha: Transparency of heatmap overlay\n",
    "    \n",
    "    Returns:\n",
    "        superimposed_img: Image with heatmap overlay\n",
    "    \"\"\"\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    \n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    \n",
    "    # Resize the heatmap to match the image size\n",
    "    from PIL import Image\n",
    "    jet_heatmap_img = Image.fromarray(np.uint8(jet_heatmap * 255))\n",
    "    jet_heatmap_img = jet_heatmap_img.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = np.array(jet_heatmap_img) / 255.0\n",
    "    \n",
    "    # Convert grayscale to RGB if needed\n",
    "    if img.shape[-1] == 1:\n",
    "        img = np.repeat(img, 3, axis=-1)\n",
    "    \n",
    "    # Denormalize image from [-1, 1] to [0, 255]\n",
    "    img = (img + 1.0) * 127.5\n",
    "    img = np.clip(img, 0, 255)\n",
    "    \n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * 255 * alpha + img * (1 - alpha)\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return superimposed_img\n",
    "\n",
    "\n",
    "# Get 3 images from validation dataset\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for images, labels in val_dataset.take(1):\n",
    "    # Take first 3 images from the batch\n",
    "    for i in range(min(3, len(images))):\n",
    "        sample_images.append(images[i])\n",
    "        sample_labels.append(labels[i])\n",
    "\n",
    "# Load the trained model (if not already loaded)\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    models = os.listdir(\"epochs\")\n",
    "    latest_model = sorted(models)[-1]\n",
    "    print(f\"Loading model: {latest_model}\")\n",
    "    model = keras.models.load_model(os.path.join(\"epochs\", latest_model))\n",
    "\n",
    "# Find the last convolutional layer name\n",
    "last_conv_layer_name = None\n",
    "for layer in reversed(model.layers):\n",
    "    if isinstance(layer, keras.layers.Conv2D):\n",
    "        last_conv_layer_name = layer.name\n",
    "        break\n",
    "\n",
    "print(f\"Using last convolutional layer: {last_conv_layer_name}\")\n",
    "\n",
    "# Create Grad-CAM visualizations\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for idx, (img, label) in enumerate(zip(sample_images, sample_labels)):\n",
    "    # Prepare image for prediction\n",
    "    img_array = tf.expand_dims(img, 0)\n",
    "    \n",
    "    # Get prediction\n",
    "    preds = model.predict(img_array, verbose=0)\n",
    "    pred_class = np.argmax(preds[0])\n",
    "    pred_prob = preds[0][pred_class]\n",
    "    \n",
    "    # Generate Grad-CAM heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    \n",
    "    # Create superimposed image\n",
    "    superimposed_img = save_and_display_gradcam(img.numpy(), heatmap)\n",
    "    \n",
    "    # Display original image\n",
    "    # Denormalize for display from [-1, 1] to [0, 1]\n",
    "    img_display = (img.numpy() + 1.0) / 2.0\n",
    "    axes[idx, 0].imshow(img_display.squeeze(), cmap='gray')\n",
    "    axes[idx, 0].set_title(f'Original\\nTrue: {idx_to_bird[int(label.numpy())]}')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    # Display heatmap\n",
    "    axes[idx, 1].imshow(heatmap, cmap='jet')\n",
    "    axes[idx, 1].set_title('Grad-CAM Heatmap')\n",
    "    axes[idx, 1].axis('off')\n",
    "    \n",
    "    # Display superimposed image\n",
    "    axes[idx, 2].imshow(superimposed_img)\n",
    "    axes[idx, 2].set_title(f'Overlay\\nPred: {idx_to_bird[pred_class]} ({pred_prob:.2%})')\n",
    "    axes[idx, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gradcam_visualization.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "which-bird-are-you",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
